# dashboard_captacao_v3.py

import streamlit as st
import pandas as pd
from io import BytesIO
from apify_client import ApifyClient

# Configura√ß√£o da p√°gina
st.set_page_config(page_title="Capta√ß√£o Imobili√°ria Salvador", page_icon="üè†", layout="wide")

# --- SEGURAN√áA ---
# O Token DEVE ser configurado nos 'Secrets' do Streamlit Cloud para este script funcionar.
try:
    APIFY_API_TOKEN = st.secrets["APIFY_API_TOKEN"]
except Exception:
    st.error("‚ùå Erro de Configura√ß√£o: O Token da Apify n√£o foi encontrado nos Secrets do Streamlit.")
    st.info("Por favor, adicione 'APIFY_API_TOKEN' nas configura√ß√µes avan√ßadas do Streamlit Cloud.")
    st.stop()

ACTOR_ID = "israeloriente/olx-brasil-imoveis-scraper"

st.title("üè† Painel de Capta√ß√£o - Salvador")
st.sidebar.header("‚öôÔ∏è Filtros")

# Filtros
localizacao = st.sidebar.selectbox("üìç Bairro", ["Stella Maris", "Praia do Flamengo", "Itapu√£", "Pitua√ßu", "Imbu√≠"])
tipo_transacao = st.sidebar.radio("üí∞ Transa√ß√£o", ["Venda", "Aluguel"])
preco_min = st.sidebar.number_input("Pre√ßo M√≠nimo", value=350000)
quartos_min = st.sidebar.slider("Quartos M√≠nimos", 1, 5, 2)
apenas_particular = st.sidebar.checkbox("‚úÖ Apenas Propriet√°rios", value=True)

if st.button("üîç Iniciar Capta√ß√£o", use_container_width=True):
    with st.spinner("Buscando leads na OLX..."):
        try:
            client = ApifyClient(APIFY_API_TOKEN)
            loc_slug = localizacao.lower().replace(" ", "-")
            search_url = f"https://olx.com.br/imoveis/{tipo_transacao.lower()}/bahia/salvador/{loc_slug}"
            
            run_input = {
                "startUrls": [{"url": search_url}],
                "maxItems": 50,
                "is_professional": not apenas_particular,
                "minPrice": preco_min,
                "minRooms": quartos_min
            }
            
            run = client.actor(ACTOR_ID).call(run_input=run_input)
            
            if run and run.get('status') == 'SUCCEEDED':
                dataset = client.dataset(run["defaultDatasetId"])
                leads = list(dataset.iterate_items())
                
                if leads:
                    df = pd.DataFrame(leads)
                    st.success(f"‚úÖ {len(df)} leads encontrados!")
                    st.dataframe(df[["title", "price", "rooms", "area", "contact", "url"]].rename(columns={
                        "title": "T√≠tulo", "price": "Pre√ßo", "rooms": "Quartos", "area": "√Årea", "contact": "Contato"
                    }))
                    
                    # Download Excel
                    output = BytesIO()
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                        df.to_excel(writer, index=False)
                    st.download_button("üìä Baixar Excel", output.getvalue(), f"leads_{loc_slug}.xlsx", use_container_width=True)
                else:
                    st.warning("Nenhum im√≥vel encontrado.")
            else:
                st.error("Falha na execu√ß√£o do scraper.")
        except Exception as e:
            st.error(f"Erro: {e}")

st.markdown("---")
st.caption("Desenvolvido por Manus AI | Capta√ß√£o Inteligente")
